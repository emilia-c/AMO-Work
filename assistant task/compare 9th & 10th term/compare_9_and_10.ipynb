{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SET-UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MEP data from: C:/Users/Emilia/Documents/Uni Helsinki/Year Three/AMO Freelance/assistant task/9 term/raw data/final/9TERM_ALL_STANDARDIZED.json\n",
      "Loaded 735 MEPs successfully.\n",
      "Loading MEP data from: C:/Users/Emilia/Documents/Uni Helsinki/Year Three/AMO Freelance/assistant task/10 term/raw data/29-10-2024/mep_assistants.json\n",
      "Loaded 719 MEPs successfully.\n"
     ]
    }
   ],
   "source": [
    "# 1. Load JSON files for each term\n",
    "def load_mep_data(json_path):\n",
    "    \"\"\"Load MEP data from a JSON file.\"\"\"\n",
    "    print(f\"Loading MEP data from: {json_path}\")\n",
    "    if not os.path.exists(json_path):\n",
    "        print(f\"File not found: {json_path}\")\n",
    "        exit(1)\n",
    "    \n",
    "    try:\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            file_content = f.read().strip()  # Strip any extra whitespace\n",
    "            if not file_content:\n",
    "                raise ValueError(\"File is empty\")\n",
    "            \n",
    "            # Validate JSON by loading\n",
    "            meps_data = json.loads(file_content)  \n",
    "            print(f\"Loaded {len(meps_data)} MEPs successfully.\")\n",
    "            return meps_data\n",
    "    \n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"JSON decode error at character {e.pos}: {e}\")\n",
    "    except ValueError as e:\n",
    "        print(f\"ValueError: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load MEP data: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# File paths (replace with your paths)\n",
    "data_9th_term = load_mep_data('C:/Users/Emilia/Documents/Uni Helsinki/Year Three/AMO Freelance/assistant task/9 term/raw data/final/9TERM_ALL_STANDARDIZED.json')\n",
    "data_10th_term = load_mep_data('C:/Users/Emilia/Documents/Uni Helsinki/Year Three/AMO Freelance/assistant task/10 term/raw data/29-10-2024/mep_assistants.json')\n",
    "\n",
    "# Convert data to DataFrame\n",
    "df_9th = pd.json_normalize(data_9th_term)\n",
    "df_9th['term'] = 9  # Add term info\n",
    "df_10th = pd.json_normalize(data_10th_term)\n",
    "df_10th['term'] = 10\n",
    "\n",
    "# Concatenate dataframes\n",
    "all_meps = pd.concat([df_9th, df_10th], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only columns that we will use in analysis\n",
    "columns_to_keep = [\n",
    "    'name', \n",
    "    'party', \n",
    "    'country', \n",
    "    'term', \n",
    "    'assistants.Accredited assistants', \n",
    "    'assistants.Accredited assistants (grouping)'\n",
    "]\n",
    "\n",
    "# filter the DataFrame\n",
    "meps_apas = all_meps[columns_to_keep]\n",
    "\n",
    "# rename the columns by removing the 'assistants.' prefix\n",
    "meps_apas.columns = [col.replace('assistants.', '') for col in meps_apas.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CLEAN & STANDARDIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Party names to abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Emilia\\AppData\\Local\\Temp\\ipykernel_10116\\4283556260.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  meps_apas.loc[:, 'group_abbrv'] = meps_apas['party'].map(party_abbreviations)\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping dictionary for party names to abbreviations\n",
    "party_abbreviations = {\n",
    "    'Renew Europe Group': 'Renew',\n",
    "    'European Conservatives and Reformists Group': 'ECR',\n",
    "    \"Group of the European People's Party (Christian Democrats)\": 'EPP',\n",
    "    'Group of the Progressive Alliance of Socialists and Democrats in the European Parliament': 'S&D',\n",
    "    'Identity and Democracy Group': 'ID',\n",
    "    'Group of the Greens/European Free Alliance': 'G/EFA',\n",
    "    'Confederal Group of the European United Left - Nordic Green Left': 'GUE/NGL',\n",
    "    'Non-attached Members': 'NA',\n",
    "    'The Left group in the European Parliament - GUE/NGL': 'GUE/NGL',\n",
    "    'Group of the European United Left - Nordic Green Left': 'GUE/NGL',\n",
    "    'Patriots for Europe Group': 'PFE',\n",
    "    'Europe of Sovereign Nations Group': 'ESN'\n",
    "}\n",
    "\n",
    "meps_apas.loc[:, 'group_abbrv'] = meps_apas['party'].map(party_abbreviations)\n",
    "#print(meps_apas['party'].unique())\n",
    "#print(meps_apas['group_abbrv'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Flatten & pivot (assistants are row level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         assistant_name         mep_name  group   country  \\\n",
      "0                 Anna Sophia BENGTSSON  Abir AL-SAHLANI  Renew    Sweden   \n",
      "1               John August HULTENGAARD  Abir AL-SAHLANI  Renew    Sweden   \n",
      "2                  Tyra Louise LUNDBERG  Abir AL-SAHLANI  Renew    Sweden   \n",
      "3     Linn Christina Brunhilde OETTERLI  Abir AL-SAHLANI  Renew    Sweden   \n",
      "4               Sylwia Joanna BETKOWSKA     Adam JARUBAS    EPP    Poland   \n",
      "...                                 ...              ...    ...       ...   \n",
      "7495          Andréa Laure Marie MOULIN    Željana ZOVKO    EPP   Croatia   \n",
      "7496                         Polona KEK       Milan ZVER    EPP  Slovenia   \n",
      "7497                     Petra SKRINJAR       Milan ZVER    EPP  Slovenia   \n",
      "7498                        Peter SUHEL       Milan ZVER    EPP  Slovenia   \n",
      "7499                     Dominik STRAKL       Milan ZVER    EPP  Slovenia   \n",
      "\n",
      "      term  \n",
      "0        9  \n",
      "1        9  \n",
      "2        9  \n",
      "3        9  \n",
      "4        9  \n",
      "...    ...  \n",
      "7495    10  \n",
      "7496    10  \n",
      "7497    10  \n",
      "7498    10  \n",
      "7499    10  \n",
      "\n",
      "[7500 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to extract only relevant assistants\n",
    "def extract_assistants(row):\n",
    "    assistants = []\n",
    "    # Focus only on \"Accredited assistants\" and \"Accredited assistants (grouping)\"\n",
    "    relevant_groups = ['Accredited assistants', 'Accredited assistants (grouping)']\n",
    "    \n",
    "    for group in relevant_groups:\n",
    "        # Check if the group exists in the row\n",
    "        if group in row and isinstance(row[group], list):\n",
    "            names = row[group]\n",
    "            for name in names:\n",
    "                assistants.append({\n",
    "                    'assistant_name': name,\n",
    "                    'mep_name': row['name'],  \n",
    "                    'group': row['group_abbrv'],\n",
    "                    'country': row['country'],\n",
    "                    'term': row['term']\n",
    "                })\n",
    "    return assistants\n",
    "\n",
    "# Flatten assistants for easier comparison\n",
    "assistant_data = pd.DataFrame(\n",
    "    [item for sublist in meps_apas.apply(extract_assistants, axis=1) for item in sublist]\n",
    ")\n",
    "print(assistant_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Remove duplicate assistant names in same term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar assistant names for the same MEP in the same term:\n",
      "Michal MOJTO and Michaela MOJTOVÁ for Monika BEŇOVÁ are similar.\n",
      "Michal MOJTO and Michaela MOJTOVÁ for Monika BEŇOVÁ are similar.\n",
      "Michal MOJTO and Michaela MOJTOVÁ for Erik KALIŇÁK are similar.\n",
      "                         assistant_name         mep_name  group   country  \\\n",
      "0                 Anna Sophia BENGTSSON  Abir AL-SAHLANI  Renew    Sweden   \n",
      "1               John August HULTENGAARD  Abir AL-SAHLANI  Renew    Sweden   \n",
      "2                  Tyra Louise LUNDBERG  Abir AL-SAHLANI  Renew    Sweden   \n",
      "3     Linn Christina Brunhilde OETTERLI  Abir AL-SAHLANI  Renew    Sweden   \n",
      "4               Sylwia Joanna BETKOWSKA     Adam JARUBAS    EPP    Poland   \n",
      "...                                 ...              ...    ...       ...   \n",
      "7495          Andréa Laure Marie MOULIN    Željana ZOVKO    EPP   Croatia   \n",
      "7496                         Polona KEK       Milan ZVER    EPP  Slovenia   \n",
      "7497                     Petra SKRINJAR       Milan ZVER    EPP  Slovenia   \n",
      "7498                        Peter SUHEL       Milan ZVER    EPP  Slovenia   \n",
      "7499                     Dominik STRAKL       Milan ZVER    EPP  Slovenia   \n",
      "\n",
      "      term  \n",
      "0        9  \n",
      "1        9  \n",
      "2        9  \n",
      "3        9  \n",
      "4        9  \n",
      "...    ...  \n",
      "7495    10  \n",
      "7496    10  \n",
      "7497    10  \n",
      "7498    10  \n",
      "7499    10  \n",
      "\n",
      "[7500 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# FIRST REMAP THE NAMES\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def find_similar_names(df, same_term=True):\n",
    "    similar_pairs = []\n",
    "\n",
    "    # Iterate through each MEP\n",
    "    for mep in df['mep_name'].unique():\n",
    "        # Filter for the current MEP\n",
    "        if same_term:\n",
    "            mep_data = df[df['mep_name'] == mep]\n",
    "        else:\n",
    "            mep_data = df[df['mep_name'] == mep]  # No term filter for this case\n",
    "\n",
    "        names = mep_data['assistant_name'].tolist()\n",
    "\n",
    "        # Check for similarity between each pair of assistant names\n",
    "        for i in range(len(names)):\n",
    "            for j in range(i + 1, len(names)):\n",
    "                # Calculate similarity score\n",
    "                score = fuzz.ratio(names[i].lower(), names[j].lower())\n",
    "                \n",
    "                # Adjusting the threshold between 90 and 99\n",
    "                if 85 <= score < 100:  # Use the desired range here\n",
    "                    similar_pairs.append((names[i], names[j], mep))\n",
    "\n",
    "    return similar_pairs\n",
    "\n",
    "# create remapping based on similar names\n",
    "name_mapping = {\n",
    "    \"Magdalena NOWACKA\": \"Magdalena HILLS-NOWACKA\", \n",
    "    \"PAULA SENDIN RODRIGUEZ\": \"Paula SENDÍN RODRIGUEZ\",\n",
    "    \"Eleonora Nikolaycheva GUIGOVA\": \"Eleonora Nikolaycheva GUIGOVA-NOSKER\",\n",
    "    \"Eleonora Nikolaycheva GUIGOVA-NOSKER\": \"Eleonora Nikolaycheva GUIGOVA-NOSKER\",\n",
    "    \"Stefanie SIFFT\": \"Stefanie SIFFT\",\n",
    "    \"Stefanie Gabi SIFFT\": \"Stefanie SIFFT\",\n",
    "    \"Anne-Cecile Juliette GAULT\": \"Anne-Cecile Juliette GAULT\",\n",
    "    \"Anne-Cecile Juliette Rachel GAULT\": \"Anne-Cecile Juliette GAULT\",\n",
    "    \"Sophie Anne Geraldine Marie GUIL\": \"Sophie Anne Geraldine Marie GUIL\",\n",
    "    \"Sophie Anne Geraldine Marie Genevieve GUIL\": \"Sophie Anne Geraldine Marie GUIL\",\n",
    "    \"Ana LOPEZ GONZALEZ\": \"ANA LÓPEZ GONZÁLEZ\",\n",
    "    \"ANA LÓPEZ GONZÁLEZ\": \"ANA LÓPEZ GONZÁLEZ\",\n",
    "    \"Claudia MARTINEZ MUNOZ\": \"Claudia MARTÍNEZ MUÑOZ\",\n",
    "    \"CLAUDIA MARTÍNEZ MUÑOZ\": \"Claudia MARTÍNEZ MUÑOZ\",\n",
    "    \"Maria Mercedes GARCIA MUNOZ\": \"MARIA MERCEDES GARCIA MUÑOZ\",\n",
    "    \"MARIA MERCEDES GARCIA MUÑOZ\": \"MARIA MERCEDES GARCIA MUÑOZ\",\n",
    "    \"Gilles Willy B SEGERS\": \"GILLES WILLY SEGERS\",\n",
    "    \"GILLES WILLY SEGERS\": \"GILLES WILLY SEGERS\",\n",
    "    \"Magdalena GONZALEZ GOZALBO\": \"Maria Magdalena GONZALEZ GOZALBO\",\n",
    "    \"Maria Magdalena GONZALEZ GOZALBO\": \"Maria Magdalena GONZALEZ GOZALBO\",\n",
    "    \"Arturo VILLARROYA GONZALEZ\": \"Arturo VILLARROYA GONZÁLEZ\",\n",
    "    \"Fernando Jose NUNEZ ROBRES PATINO\": \"Fernando Jose NUNEZ-ROBRES PATINO\",\n",
    "    \"Fernando Jose NUNEZ-ROBRES PATINO\": \"Fernando Jose NUNEZ-ROBRES PATINO\",\n",
    "    \"Bibiana CARRETO PEREZ BARBADILLO\": \"BIBIANA CARRETO PÉREZ BARBADILLO\",\n",
    "    \"BIBIANA CARRETO PÉREZ BARBADILLO\": \"BIBIANA CARRETO PÉREZ BARBADILLO\",\n",
    "    \"Magdalena GONZALEZ GOZALBO\": \"Maria Magdalena GONZALEZ GOZALBO\",\n",
    "    \"PAULA SENDIN RODRIGUEZ\": \"Paula SENDÍN RODRIGUEZ\",\n",
    "    \"Paula SENDIN RODRIGUEZ\": \"Paula SENDÍN RODRIGUEZ\",\n",
    "    \"MARIA MERCEDES GARCIA MUNOZ\": \"MARIA MERCEDES GARCIA MUÑOZ\", \n",
    "    \"ARTURO VILLARROYA GONZALEZ\": \"Arturo VILLARROYA GONZÁLEZ\",\n",
    "    \"ARTURO VILLARROYA GONZALEZ\":\"Arturo VILLARROYA GONZÁLEZ\"\n",
    "}\n",
    "\n",
    "# remap \n",
    "assistant_data['assistant_name'] = assistant_data['assistant_name'].replace(name_mapping)\n",
    "\n",
    "# Find similar names considering only the same term\n",
    "similar_names_same_term = find_similar_names(assistant_data, same_term=True)\n",
    "print(\"Similar assistant names for the same MEP in the same term:\")\n",
    "for name1, name2, mep in similar_names_same_term:\n",
    "    print(f\"{name1} and {name2} for {mep} are similar.\")\n",
    "\n",
    "print(assistant_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact matches in MEP categories (for the same term):\n",
      "\n",
      "MEP: Alicia HOMS GINEL | Term: 9\n",
      " - Alberto BONDESIO MARTINEZ\n",
      " - Cristian VILLAR PRIETO\n",
      " - Elena PEREDA LAGARTOS\n",
      " - Daniel DIEZ CECILIA\n",
      " - Josep MERCADAL BAQUERO\n",
      " - Joan SERRA MINGOT\n",
      " - Maria Magdalena GONZALEZ GOZALBO\n",
      "\n",
      "MEP: Antonio LÓPEZ-ISTÚRIZ WHITE | Term: 9\n",
      " - Carlos Casimiro SALVADOR ARMENDARIZ\n",
      "\n",
      "MEP: Esteban GONZÁLEZ PONS | Term: 9\n",
      " - Carlos FERNANDEZ OJEA\n",
      "\n",
      "MEP: Francisco José MILLÁN MON | Term: 9\n",
      " - MARIA MASEDA VARELA\n",
      "\n",
      "MEP: Iratxe GARCÍA PÉREZ | Term: 9\n",
      " - Paula SENDÍN RODRIGUEZ\n",
      " - Maria Magdalena GONZALEZ GOZALBO\n",
      " - Izaskun BERNAL CERDEIRA\n",
      " - Mercedes MARISCAL CAMPOS\n",
      " - Nayra Maria PRADO MARRERO\n",
      " - Daniel DIEZ CECILIA\n",
      " - Alberto BONDESIO MARTINEZ\n",
      " - MEL RAVELO CORDOVES\n",
      " - BLANCA SAENZ DE BURUAGA SANCHEZ\n",
      " - Jaime Daniel DE FRUTOS GONZALEZ\n",
      " - Roi VILLAR VAZQUEZ\n",
      " - Carmen MAGDALENA VALLEJO\n",
      " - Ana MARTINEZ SANJURJO\n",
      " - Ignacio Aitor DE LA PUERTA MARCO\n",
      " - Victor Patricio DONATE PAVON\n",
      "\n",
      "MEP: Isabel BENJUMEA BENJUMEA | Term: 9\n",
      " - Teresa VILLA GOMEZ\n",
      " - Jesus GARCIA ALBERTI\n",
      " - Silvia HITOS\n",
      " - Pedro MIELGO CIMAS\n",
      " - Carlos Casimiro SALVADOR ARMENDARIZ\n",
      "\n",
      "MEP: Margarita DE LA PISA CARRIÓN | Term: 9\n",
      " - Manuel FRAGA PEDROCHE\n",
      " - Arturo VILLARROYA GONZÁLEZ\n",
      "\n",
      "MEP: Matthias ECKE | Term: 9\n",
      " - Christian NEUMANN\n",
      " - Hannah CORNELSEN\n",
      " - Jacinta Maria KAISER\n"
     ]
    }
   ],
   "source": [
    "# THEN REMOVE ANY EXACT MATCHES \n",
    "# Find exact matches within each MEP category\n",
    "# Find exact matches within each MEP and term\n",
    "def find_exact_matches(df):\n",
    "    exact_matches = {}\n",
    "\n",
    "    # Group by 'mep_name' and 'term' and find duplicates in 'remapped_name'\n",
    "    for (mep, term), group in df.groupby(['mep_name', 'term']):\n",
    "        duplicates = group['assistant_name'].value_counts()\n",
    "        # Only keep names that occur more than once\n",
    "        duplicate_names = duplicates[duplicates > 1].index.tolist()\n",
    "        \n",
    "        if duplicate_names:\n",
    "            exact_matches[(mep, term)] = duplicate_names\n",
    "\n",
    "    return exact_matches\n",
    "\n",
    "# Get exact matches\n",
    "exact_matches = find_exact_matches(assistant_data)\n",
    "\n",
    "# Print out exact matches\n",
    "print(\"Exact matches in MEP categories (for the same term):\")\n",
    "for (mep, term), names in exact_matches.items():\n",
    "    print(f\"\\nMEP: {mep} | Term: {term}\")\n",
    "    for name in names:\n",
    "        print(f\" - {name}\")\n",
    "\n",
    "# remove duplicates \n",
    "unique_meps_apas = assistant_data.drop_duplicates(subset=['mep_name', 'term', 'assistant_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Network Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         assistant_name         mep_name  group   country  \\\n",
      "0                 Anna Sophia BENGTSSON  Abir AL-SAHLANI  Renew    Sweden   \n",
      "1               John August HULTENGAARD  Abir AL-SAHLANI  Renew    Sweden   \n",
      "2                  Tyra Louise LUNDBERG  Abir AL-SAHLANI  Renew    Sweden   \n",
      "3     Linn Christina Brunhilde OETTERLI  Abir AL-SAHLANI  Renew    Sweden   \n",
      "4               Sylwia Joanna BETKOWSKA     Adam JARUBAS    EPP    Poland   \n",
      "...                                 ...              ...    ...       ...   \n",
      "7495          Andréa Laure Marie MOULIN    Željana ZOVKO    EPP   Croatia   \n",
      "7496                         Polona KEK       Milan ZVER    EPP  Slovenia   \n",
      "7497                     Petra SKRINJAR       Milan ZVER    EPP  Slovenia   \n",
      "7498                        Peter SUHEL       Milan ZVER    EPP  Slovenia   \n",
      "7499                     Dominik STRAKL       Milan ZVER    EPP  Slovenia   \n",
      "\n",
      "      term  \n",
      "0        9  \n",
      "1        9  \n",
      "2        9  \n",
      "3        9  \n",
      "4        9  \n",
      "...    ...  \n",
      "7495    10  \n",
      "7496    10  \n",
      "7497    10  \n",
      "7498    10  \n",
      "7499    10  \n",
      "\n",
      "[7464 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes and edges\n",
    "for _, row in unique_meps_apas.iterrows():\n",
    "    G.add_node(row['mep_name'], type='mep')\n",
    "    G.add_node(row['assistant_name'], type='assistant')\n",
    "    G.add_edge(row['mep_name'], row['assistant_name'])\n",
    "\n",
    "# Create positions for the nodes using spring layout\n",
    "pos = nx.spring_layout(G)\n",
    "\n",
    "# Extract edges and nodes for visualization\n",
    "edge_x = []\n",
    "edge_y = []\n",
    "for edge in G.edges():\n",
    "    x0, y0 = pos[edge[0]]\n",
    "    x1, y1 = pos[edge[1]]\n",
    "    edge_x.append(x0)\n",
    "    edge_x.append(x1)\n",
    "    edge_x.append(None)  # None for break in the line\n",
    "    edge_y.append(y0)\n",
    "    edge_y.append(y1)\n",
    "    edge_y.append(None)  # None for break in the line\n",
    "\n",
    "edge_trace = go.Scatter(\n",
    "    x=edge_x, y=edge_y,\n",
    "    line=dict(width=0.5, color='#888'),\n",
    "    hoverinfo='none',\n",
    "    mode='lines')\n",
    "\n",
    "# Add nodes for MEPs\n",
    "node_x = []\n",
    "node_y = []\n",
    "node_text = []\n",
    "for node in G.nodes():\n",
    "    x, y = pos[node]\n",
    "    node_x.append(x)\n",
    "    node_y.append(y)\n",
    "    node_text.append(node)\n",
    "\n",
    "node_trace = go.Scatter(\n",
    "    x=node_x, y=node_y,\n",
    "    mode='markers+text',\n",
    "    text=node_text,\n",
    "    hoverinfo='text',\n",
    "    marker=dict(\n",
    "        showscale=True,\n",
    "        colorscale='YlGnBu',\n",
    "        size=10,\n",
    "        color='blue'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure(data=[edge_trace, node_trace],\n",
    "                layout=go.Layout(\n",
    "                    title='Assistants Network Graph',\n",
    "                    titlefont=dict(size=16),\n",
    "                    showlegend=False,\n",
    "                    hovermode='closest',\n",
    "                    margin=dict(b=0,l=0,r=0,t=40),\n",
    "                    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False))\n",
    "                )\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mep_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
